---
title: 'Sense and sensibility: On the diagnostic value of control chart rules for
  detection of shifts in time series data'
output:
  word_document:
    # fig_height: 5
    reference_docx: arkiv/spc_diagnostics_template.docx
  # pdf_document: default
  # html_document:
  #   dev: svg
  #   fig_height: 6
# geometry: margin=1in
# classoption: a4paper
# header-includes:
#   - \usepackage[left]{lineno}
#   - \linenumbers
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,
                      cache = TRUE,
                      message = FALSE,
                      warning = FALSE)
load('data/spc_diagnostics_plots.RData')
```


```{r fig1, results='hide', fig.cap='Fig 1: Example control charts. A: random variation. B: Non-random variation caused by a large, possibly transient, shift in data identified by one data point being outside the upper control limit. C: Non-random variation caused by a sustained moderate shift in data identified by an unusually long run of 13 data points below the centre line (WE rule 4 and Anhoej rule 1) and unusually few crossing (Anhoej rule 2)'}

set.seed(19)
y1 <- y2 <- y3 <- rnorm(24)
y2[22] <- 4
y3[13:24] <- rnorm(12, mean = 2)

d <- data.frame(x = rep(1:24, 3),
                y = c(y1, y2, y3),
                g = c(rep(c('A', 'B', 'C'), each = 24)))

p0 <- qicharts2::qic(x, y,
                     data = d, 
                     chart = 'i',
                     facets = ~ g,
                     ncol = 1,
                     ylab = 'Measure',
                     xlab = 'Time') +
  ggplot2::labs(title = NULL)

tiff('fig1.tiff',
     width = 2250,
     height = 2250,
     res = 300,
     compression = 'lzw')
plot(p0)
dev.off()
```

```{r fig2, results='hide', fig.cap='Fig 2: Sensitivity of control chart rules. we1 = Western Electric (WE) rule1, we12 = WE rule 1 and 2 etc. Anhoej = Anhoej rules. k = series length (number of data points).'}

p1 <- p1 + ggplot2::labs(title = NULL) 

tiff('fig2.tiff',
     width = 2250,
     height = 2250,
     res = 300,
     compression = 'lzw')
plot(p1)
dev.off()
```

```{r fig3, results='hide', fig.cap='Fig 3: False alarm rates of control chart rules.', fig.height=4}

p2 <- p2 + ggplot2::labs(title = NULL)

tiff('fig3.tiff',
     width = 2250,
     height = 1300,
     res = 300,
     compression = 'lzw')
plot(p2)
dev.off()
```

```{r fig4, results='hide', fig.cap='Fig 4: Likelihood ratios of control chart rules when a shift of 2 standard deviation units is present.'}

p3 <- p3 + ggplot2::labs(title = NULL)

tiff('fig4.tiff',
     width = 2250,
     height = 2250,
     res = 300,
     compression = 'lzw')
plot(p3)
dev.off()
```

Jacob Anhøj (corresponding author)<br />
Centre of Diagnostic Investigation, Rigshospitalet, University of Copenhagen, Denmark<br/>
jacob@anhoej.net

Tore Wentzel-Larsen<br />
Centre for Child and Adolescent Mental Health, Eastern and Southern Norway &
Centre for Violence and Traumatic Stress Studies, Oslo, Norway<br />
tore.wentzellarsen@gmail.com

Revision date: `r Sys.Date()`

# Abstract

**Background**

The aim of this study is to quantify and compare the diagnostic value of The Western Electric statistical process control chart rules and the Anhoej rules for detection of non-random variation in time series data in order to make recommendations for their application under different conditions.

**Methods**

Control charts are point-and-line graphs showing a measure over time and employing statistical tests for identification of non-random variation.

In this study we use simulated time series data with and without non-random variation introduced as shifts in process centre over time. The primary outcome is likelihood ratios of combined tests. Likelihood ratios are useful measures of a test's ability to discriminate between the true presence or absence of a specific condition.

**Results and conclusions**

This study confirms that likelihood ratios are useful measures of the diagnostic value of control chart rules. The Western Electric rules 1-4 combined perform very well with short data series (< 20 data points). For longer data series, the Anhoej rules alone or in combination with the WE rule 1 may be a better choice. Most importantly, the choice of which and how many rules to apply in a given situation should be made deliberately depending on the specific purpose of the analysis.

# Introduction

Over the past decade or so, the term "improvement science" has gained attention and sparked debate [1]. In healthcare, which is our domain, improvement science is viewed by many as the natural successor -- or rather supplement -- to evidence based medicine. If evidence based medicine is about doing the right things then, improvement science is about doing things right, and one is meaningless without the other [2].

In a systematic review The Health Foundation concludes that: "Improvement science is about finding out how to improve and make changes in the most effective way. It is about systematically examining the methods and factors that best work to facilitate quality improvement" [1].

Following this, change and improvement are closely related in that improvement is always the result of change. However, not all changes result in improvement. In order to know that improvement is happening, we must be able to measure the quality characteristics of the processes we are trying to improve. As improvement always happens over time, time is an essential part of the analysis, and since measurement is subject to variation whether or not improvement is happening, the aim of the analysis is to discriminate between naturally occurring variation in data over time (noise, random or common cause variation) and variation that is the result of changes to a process (signal, non-random or special cause variation).

Statistical process control (SPC) comprises a set of tools including control charts, which help to distinguish signal from noise in time series data.

## Statistical process control charts

SPC charts are point-and-line graphs showing a measure over time and employing statistical tests for identification of non-random variation.

SPC charts are based on the assumption that, if the process in question is random the data points will be randomly distributed around the process centre expressed by the mean or median and nearly all of them will appear between limits estimating the random variation inherent in the process. These limits are called control limits and are added as horizontal lines to the chart. Control limits are usually positioned at a distance of $\pm{3}$ times the estimated within sample standard deviation (SD) from the centre line. Consequently, control limits are also referred to as 3-sigma limits. Fig 1A shows an example of a process containing random variation only.

```{r, fig.height=7}
# p0
```

> Fig 1. Example control charts. A: random variation. B: Non-random variation caused by a large, possibly transient, shift in data identified by one data point being outside the upper control limit. C: Non-random variation caused by a sustained moderate shift in data identified by an unusually long run of 13 data points below the centre line (Western Electric rule 4 and Anhoej rule 1) and unusually few crossing (Anhoej rule 2). See text for details.

The calculation of sigma limits depends on assumptions regarding the theoretical distribution of data, and many types of control charts exist for different types of measure and count data.

Control chart theory is a vast area, and the interested reader is recommended to consult the specialist literature. Montgomery provides a comprehensive coverage of the subject with emphasis on the application of SPC in engineering and management [3]. A concise introduction to the application of control charts in healthcare is provided by Mohammed [4]. Wheeler gives a more general introduction to the thinking behind and practical use of SPC [5].

> Statistical Process Control is not about statistics, it is not about "process-hyphen-control", and it is not about conformance to specifications. [...] It is about the continual improvement of processes and outcomes. And it is, first and foremost, *a way of thinking* with some tools attached. [5, p. 152]

## Testing for non-random variation

Non-random variation may take many forms depending on the nature of its underlying causes. 

Originally, SPC charts were designed to identify sudden, larger (> 2 SD) and possibly transient shifts in data (outliers). For this purpose testing for one or more data points outside the control limits is sufficient (Fig 1B). However, using this test only, other types of non-random variation may go unnoticed for longer periods of time (Fig 1C).

Since quality improvement often happens gradually or stepwise, the focus of this study is the ability to identify persistent shifts in data over time suggesting significant and lasting process improvement or deterioration. For this purpose, a number of additional control chart tests (or rules) have been developed.

### The Western Electric rules

The Best known tests for non-random variation are probably the Western Electric (WE) rules described in the Statistical Quality Control Handbook from 1956 [6, pp 23-27]. The WE rules consist of four simple tests that can be applied to control charts by visual inspection to identify non-random patterns in the distribution of data points relative to the control and centre lines:

1. **One** or more points beyond a 3-sigma limit.

2. **Two out of three** successive points beyond a 2-sigma limit (two thirds of the distance between the centre line and the control line).

3. **Four out of five** successive points beyond a 1-sigma limit.

4. **Eight** or more successive points on one side of the centre line.

When using the WE rules, it is generally recommended that control charts should have between 20 and 30 data points. With fewer data points, they lose sensitivity (more false negatives), and with more data points they lose specificity (more false positives).

### The Anhoej rules

Some lesser known tests for non-random variation are the Anhoej rules proposed and validated in two previous publications [7, 8]. The Anhoej rules consist of two tests that are based solely on the distribution of data points in relation to the centre line:

1. **Unusually long runs**: A run is one or more successive data points on the same side of the centre line. Data points that fall on the centre line do neither break nor contribute to the run. The upper 95% prediction limit for longest run is approximately $log_2(n)+3$ (rounded to the nearest integer), where $n$ is the number of useful data points. For example, in a run chart with 24 data points a run of *more* than `r round(log2(24) + 3)` would suggest a shift in the process.

2. **Unusually few crossings**: A crossing is when two successive data points are on opposite sides of the centre line (ignoring data points on the centre line). In a random process, the number of crossings is expected to follow a binomial distribution with a probability of success of 0.5, $b(n-1,0.5)$. Thus, in a run chart with 24 useful data points, *fewer* than `r qbinom(0.05, 24 - 1, 0.5)` crossings would suggest that the process is shifting.

Critical values for longest run and number of crossings may be calculated using the formulas provided or looked up in statistical tables [7].

The Anhoej rules were developed to reliably identify persistent shifts in data over time, and while they are useless in detecting transient shifts and slower than the WE rules in detecting larger shifts, they have some advantages:

* The Anhoej rules do not depend on sigma limits, and when used with the median as the centre line they are agnostic to assumptions regarding the theoretical distribution of data. Therefore they are useful as stand-alone rules with run charts, which are a lot easier to construct than control charts and require pen and paper only.

* The Anhoej rules adapt dynamically to the number of available data points and can be applied to charts with as few as 10 and up to indefinitely many data points without losing sensitivity and specificity.

### Other rules

Many, many more tests and rule sets have been proposed, and in practice there is no limit to the number of ways one could identify non-random patterns in data. However, as the number of applied tests increase, the risk of false positive results increase as well, and some popular tests have proven to be at best useless in practice [9, 8].

For these reasons, the decision on which and how many rules to use in a given situation should be made deliberately, preferably before data collection begins, and based on one's understanding of the processes involved. This study is an attempt to add objectivity and reproducibility to this selection process.

## Likelihood ratios

Likelihood ratios tell how well (clinical) tests discriminate between the presence and the absence of a specific condition [10, 11]. In this study, we applied likelihood ratios to evaluate how well the WE rules are able to tell random variation from non-random variation in simulated time series.

Likelihood ratios are closely related to other measures of diagnostic value like sensitivity, specificity, and predictive values. But in contrast to these, likelihood ratios are independent of the prevalence of the conditions in the population of interest.

The use of likelihood ratios to examine the diagnostic value of run chart rules is explained in a previous paper on this subject [8].

In short, the positive likelihood ratio (LR+) is the true positive rate (TP) divided by the false positive rate (FP). LR+ greater than 10 is considered strong evidence that the condition being tested for is present. The negative likelihood ratio (LR-) is the false negative rate (FN) divided by the true negative rate (TN). LR- smaller than 0.1 is considered strong evidence against the condition [11].

$$ LR+=TP/FP=sensitivity/(1-specificity) $$
$$ LR-=FN/TN=(1-sensitivity)/specificity $$

Thus, for any test, the higher LR+ and the lower LR-, the better the test.

## Study aim

The aim of this study is to quantify and compare the diagnostic value of the Western Electric control chart rules for detection of non-random variation in time series data in order to make recommendations for their application. In addition, we compare the performance of the WE rules and the Anhoej rules.

# Methods

We use the R programming language v. 3.4.4 [12] to simulate time series data from random normal numbers with known sample averages and a fixed sample standard deviation (SD = 1). We developed custom functions for calculating likelihood ratios and for testing time series data for non-random variation using the WE zone rules and the Anhoej runs rules. For data manipulation and plotting, we use functions from the tidyverse package v. 1.2.1. [13].

To investigate the effect of series length (number of data points) and shift size (sample average) on the diagnostic value of different rules, 10,000 time series are simulated for each combination of series length (10, 12, ..., 40 data points) and shift size (0, 0.2, ..., 3.0 SD units). In total 2,560,000 time series are simulated and tested in relation to a fixed set of centre line and sigma limits of $0 \pm{1, 2, 3}$SD.

For each series the proportions of true or false positive and negative results respectively are calculated for selected combinations of tests. Positive and negative likelihood ratios are calculated for a shift size of 2 SD and series lengths of 10, 20, and 40 data points respectively.

The R source code is available at https://github.com/anhoej/spc_diagnostics.

# Results

Figure 2 shows the probability of detecting a shift in data over time in relation to the shift size for different series lengths and combinations of control chart rules. Other things being equal, the probability increases with increasing series length and shift size. Also, the probability increases with the number of tests combined.

```{r}
# p1
```

> Fig 2. Sensitivity of control chart rules. we1 = WE rule1, we12 = WE rule 1 or 2 etc. Anhoej = Anhoej rules. k = series length (number of data points).

The intercepts in Figure 2 corresponding to no shift (SD = 0) indicate the probability of getting false positive tests when no shifts are present in data. The false positive rates are explored further in Figure 3, which shows that the risk of getting false positive tests also increases with increasing series lengths and number of tests combined The exception being the Anhoej rules, which fluctuate but stay below 10%.

```{r}
# p2
```


> Fig 3. False alarm rates of control chart rules.

Figure 4 illustrates the value of positive and negative test results using likelihood ratios for combinations of series lengths and tests when a shift of 2 SD is present in data. As mentioned, a better test is one with a large range, preferably with LR+ above 10 and LR- below 0.1.

```{r}
# p3
```

> Fig 4. Likelihood ratios of control chart rules when a shift of 2 standard deviation units is present.

Other things being equal, the value of a positive test decreases while the value of a negative test increases with more tests and longer series. For short data series (k = 10), all combinations of rules perform well. Especially, if one needs to be able to exclude shifts in data with high reliability, the combination of WE rules 1-4 appear to be of high diagnostic value. For longer data series, the WE rule 1 and the Anhoej rules appear reliable and robust. One should be cautious when using combinations of multiple rules with longer data series as the values of positive tests decrease significantly (LR+ < 10).

# Discussion

To our knowledge, this is the first study to investigate and quantify the value of the Western Electric rules using likelihood ratios on simulated time series data.

Traditionally, the diagnostic properties of SPC charts have been described using the average run length (ARL) measure, which is the average number of data points expected until a rule signals non-random variation. ARLs may be calculated for in-control and out-of-control conditions, where in- and out-of-control means random and non-random variation respectively provided that the theoretical distribution of data and the nature of the out-of-control condition are known [3].  ARLs are comparable to sensitivity and specificity measures traditionally used in health sciences in that they express the chance of having a positive test given the condition being present or absent. Likewise, power functions (Fig 2) and risk of false alarm rates (Fig 3) are commonly used to describe the value of SPC rules [3].

However, like sensitivity and specificity, ARLs and power functions do not answer the questions of interest for the practical use of a test: given a test result, what is the chance that this result truly reflects the presence or absence of the condition?

Predictive values are alternative measures of diagnostic properties and are designed to answer these kinds of questions. But unlike likelihood ratios they depend on the prevalence of the condition in the population of interest, which is often unknown or even unknowable.

Likelihood ratios are easy to compute provided one has access to test results together with information on the true presence or absence of the condition of interest for each test. With the ubiquity of personal computers and free, open source software, large datasets are easily simulated for studies like this comparing known outcomes to combinations of different tests under different conditions.

Likelihood ratios are also easy to explain: given a specific test result, how many times more (or less) likely is it that the condition is present? For example, in a control chart with 10 data points that tests positive on WE rule 1, a shift in the order of 2 SD is about 30 times more likely than no shift. If the same chart tests negative on WE rule 1, a shift of 2 SD is about 5 times less likely than no shift (Fig 4).

This study has two important limitations. First, the results are not to be extrapolated outside the conditions being tested. Second, since the results come from simulated data series, they should not be taken as exact values rather than indicators of how different conditions affect the diagnostic value of SPC charts.

Regarding extrapolating the results: This study was designed to specifically investigate the effect of series length and combinations of SPC rules in SPC charts when the process centre and spread are known in advance before the introduction of a persistent shift in the process centre. In practice, SPC charts are often used without prior knowledge of process centre and spread. In such cases, the purpose of the chart may actually be to estimate these properties. Also, changes in real life data come in many more forms than persistent shifts of 2 SD. 

In our practice (hospital infections, drug usage, procedure compliance, etc.), sudden shifts are less common than long term trends, waves, and individual outliers. Trends and waves are often identified by the Anhoej rules long before any of the WE rules signal. Outliers are often picked up quickly by WE rule 1. However, to quantify the diagnostic value of SPC charts for other patterns, one must design studies for the specific purpose.

Regarding the use of simulations and in extension of the previous paragraph: No simulated data can truly reflect the properties of real life data, and the results should be interpreted cautiously. Specifically, sudden, persistent shift of exactly 2 SD, as used in our model, may never happen in reality, and our results are merely suggestive of what is expected to happen when data series grow longer and more and more tests are applied.

# Conclusions

This study confirms that likelihood ratios are useful measures of the diagnostic value of SPC rules. The Western Electric rules 1-4 perform very well with short data series (< 20 data points). For longer data series, the Anhoej rules alone or in combination with the WE rule 1 may be a better choice. Most importantly, the choice of which and how many rules to apply in a given situation should be made deliberately depending on the specific purpose of the SPC analysis and the number of available data points.

All other things being equal, the more data points, the fewer rules should be applied if one wants to maintain satisfactory values of positive tests. On the other hand if the purpose of the SPC analysis is to exclude non-random variation with a high degree of certainty, and if the cost of false positive tests is low, more rules may be useful.

# References

1. Health Foundation. Evidence scan: Improvement science. Health Foundation 2011. Available from: http://www.health.org.uk/publication/improvement-science. Accessed April 18, 2018.

2. Glasziou P, Ogrinc G, Goodman S. Can evidence-based medicine and clinical quality improvement learn from each other? BMJ Quality & Safety 2011;20:i13-i17. doi:10.1136/bmjqs.2010.046524.

3. Montgomery DC. Introduction to Statistical Quality Control. 6th ed. USA: John Wiley & Sons; 2009.

4. Mohammed MA, Worthington P, Woodall WH. Plotting basic control charts: tutorial notes for healthcare practitioners. Qual Saf Health Care. 2008 Apr;17(2):137-45. doi:10.1136/qshc.2004.012047.

5. Wheeler DJ. Understanding Variation -- The Key to Managing Chaos. 2nd ed. Knoxville: SPC Press; 2000.

6. Western Electric Company. Statistical Quality Control Handbook. 2nd ed. Easton: Mack Printing Company; 1958. Available from: http://www.westernelectric.com/support-statistical-quality-control-handbook.html

7. Anhøj J, Olesen AV. Run Charts Revisited: A Simulation Study of Run Chart Rules for Detection of Non-Random Variation in Health Care Processes. PLOS ONE 9(11): e113825. doi:10.1371/journal.pone.0113825.

8. Anhøj J. Diagnostic Value of Run Chart Analysis: Using Likelihood Ratios to Compare Run Chart Rules on Simulated Data Series. PLoS One. 2015 Mar 23;10(3):e0121349. doi:10.1371/journal.pone.0121349.

9. Davis RB, Woodall WH. Performance of the Control Chart Trend Rule Under Linear Shift. Journal of Quality Technology 1988;20: 260-262.

10. Attia J. Moving beyond sensitivity and specificity: using likelihood ratios to help interpret diagnostic tests. Australian Prescriber 2003;26: 111-113.

11. Deeks JJ, Altman DG. Diagnostic tests 4: likelihood ratios. BMJ 2004;329: 168-169.

12. R Core Team. R: A Language and Environment for Statistical Computing. Version 3.4.3 [software]. Available from: https://www.R-project.org/. Accessed April 18, 2018.

13. Wickham H. tidyverse: Easily Install and Load the 'Tidyverse'. R package. Version 1.2.1 [software]. Available from: https://CRAN.R-project.org/package=tidyverse. Accessed April 18, 2018.

# Abbreviations

* SPC: statistical process control

* WE: Western Electric

* SD: Standard deviation

# Declarations

## Ethics approval and consent to participate

Not applicable.
  
## Consent for publication

Not applicable.

## Availability of data and material

All data generated or analysed during this study are included in this published article and its supplementary information files.

## Competing interests

The authors declare that they have no competing interests.

## Funding

This study received no funding

## Authors' contributions

JA and TWL 

* made contributed to conception, design, acquisition of data, and analysis and interpretation of data;

* was involved in writing and revising the manuscript;

* gave final approval of the version to be published;

* agreed to be accountable for all aspects of the work.

## Acknowledgements

Not applicable.